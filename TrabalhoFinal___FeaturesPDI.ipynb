{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrabalhoFinal_-_FeaturesPDI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l2_LkUpCjuW",
        "colab_type": "text"
      },
      "source": [
        "# 1. Machine Lerning aplicada à predição de Câncer de Pele"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6BsX6XMCqMc",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Introdução do problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yZVMpXMGVGD",
        "colab_type": "text"
      },
      "source": [
        "O problema necessita de aprendizagem supervisionada. É uma atividade de classificação. \n",
        "\n",
        "Batch Learning ou online Learning? \n",
        "\n",
        "Serão testados diferentes algoritmos supervisionados. A medida de desempenho utilizada será a acurácia, especificidades e sensibilidade (matriz de confusão)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmzq1jYzEd70",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Get Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh7J1rgnzOtg",
        "colab_type": "text"
      },
      "source": [
        "Informar a descrição dessas variáveis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbb4KzVOZBVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read the dataset to a Pandas' dataframe\n",
        "data = pd.read_csv(\"DadosGeral.txt\", sep='\\t')\n",
        "\n",
        "# data shape\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1raFG8Np_KZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5wuSl7sDEO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quantidade de dados por tipo de diagnóstico\n",
        "\n",
        "data.clinical_diagnosis.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSgVR8T-DmRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIsFKRylExwZ",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Clean, Prepare & Manipulate Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqYiNc-uN90t",
        "colab_type": "text"
      },
      "source": [
        "the values in the maximum_nights and number_of_reviews columns span much larger ranges. For example, the maximum_nights column has values as low as 27 and high as 1125, in the first few rows itself. If we use these 2 columns as part of a k-nearest neighbors model, these attributes could end up having an outsized effect on the distance calculations because of the largeness of the values. To prevent any single column from having too much of an impact on the distance, we can normalize all of the columns to have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "Normalizing the values in each columns to the [standard normal distribution](https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution) (mean of 0, standard deviation of 1) preserves the distribution of the values in each column while aligning the scales. To normalize the values in a column to the standard normal distribution, you need to:\n",
        "\n",
        "- from each value, subtract the mean of the column\n",
        "- divide each value by the standard deviation of the column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PfJvPg8zJ2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_aux = data.drop('clinical_diagnosis', axis=1)\n",
        "data_aux.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThsODq-RbhBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# apply z-score (mean=0, std=1)\n",
        "normalized = pd.DataFrame(StandardScaler().fit_transform(data_aux),\n",
        "                            columns=data_aux.columns,\n",
        "                            index=data_aux.index)\n",
        "normalized.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ekF-AFbdVkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "# Identfy the KDE shape for all columns (gaussian distribution) after outlier elimination\n",
        "import matplotlib.pyplot as plt\n",
        "normalized.plot(kind='density',\n",
        "                        layout=(10,2),\n",
        "                        subplots=True,\n",
        "                        figsize=(25,25),\n",
        "                        sharex=False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHHnrWJaGWhB",
        "colab_type": "text"
      },
      "source": [
        "When numbers are used to represent different options or categories, they are referred to as **categorical values**. Classification focuses on estimating the relationship between the independent variables (x) and the dependent (y), **categorical variable**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWB4FW2dNC-E",
        "colab_type": "text"
      },
      "source": [
        "A coluna com a classificação do nevo precisa ser codificiada, visto que, é uma variável categórica que precisa ser convertida para valor númerico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC6xCvxyNUSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col = pd.Categorical(data[\"clinical_diagnosis\"])\n",
        "data_aux[\"clinical_diagnosis\"] = col.codes\n",
        "data_aux.head(200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbSfvwXCshh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix = data_aux.corr()\n",
        "corr_matrix[\"clinical_diagnosis\"].\\\n",
        "  sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgZml30ytmJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_aux.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftQ4JncobRqc",
        "colab_type": "text"
      },
      "source": [
        "Three beneits of performing feature selection\n",
        "before modeling your data are:\n",
        "\n",
        "- **Reduces Overfitting**: Less redundant data means less opportunity to make decisions based on noise.\n",
        "- **Improves Accuracy**: Less misleading data means modeling accuracy improves.\n",
        "- **Reduces Training Time**: Less data means that algorithms train faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEv63CUdE5yP",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp8pxm5yGS0u",
        "colab_type": "text"
      },
      "source": [
        "**Load Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfJyQ6Sv8Uzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "from sklearn.pipeline import Pipeline\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KARIu9Kw8V4K",
        "colab_type": "text"
      },
      "source": [
        "**Split data into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haeEEaJl7ZZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_aux.drop('clinical_diagnosis', axis=1), \n",
        "                                                    data_aux.clinical_diagnosis,\n",
        "                                                    test_size=0.20, \n",
        "                                                    random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AE85jFZ9PWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# global variables\n",
        "seed = 42\n",
        "num_folds = 10\n",
        "scoring = {'Accuracy': make_scorer(accuracy_score)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQEKpWP08joz",
        "colab_type": "text"
      },
      "source": [
        "**Training using a Pipeline and Gridsearch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYYnhjAl7Tg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A single Pipeline\n",
        "pipe = Pipeline(steps = [(\"clf\",MLPClassifier())])\n",
        "\n",
        "# create a dictionary with the hyperparameters\n",
        "search_space = [\n",
        "                {\"clf\":[MLPClassifier()],\n",
        "                 \"clf__hidden_layer_sizes\": [(120,240),(120,480,120),(120,240,480,240,120)],\n",
        "                 \"clf__activation\": [\"logistic\",\"relu\"],\n",
        "                 \"clf__solver\": [\"sgd\"],\n",
        "                 \"clf__max_iter\": [50000],\n",
        "                 \"clf__early_stopping\":[True],\n",
        "                 \"clf__n_iter_no_change\":[20],\n",
        "                 \"clf__validation_fraction\":[0.20], \n",
        "                 }\n",
        "                ]\n",
        "\n",
        "# create grid search\n",
        "kfold = StratifiedKFold(n_splits=num_folds,random_state=seed)\n",
        "\n",
        "# return_train_score=True\n",
        "# official documentation: \"computing the scores on the training set can be\n",
        "# computationally expensive and is not strictly required to\n",
        "# select the parameters that yield the best generalization performance\".\n",
        "grid = GridSearchCV(estimator=pipe, \n",
        "                    param_grid=search_space,\n",
        "                    cv=kfold,\n",
        "                    scoring=scoring,\n",
        "                    return_train_score=True,\n",
        "                    n_jobs=-1,\n",
        "                    refit=\"Accuracy\")\n",
        "\n",
        "tmp = time.time()\n",
        "\n",
        "# fit grid search\n",
        "best_model = grid.fit(X_train,y_train)\n",
        "\n",
        "print(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx8OFC6a9VLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Best: %f using %s\" % (best_model.best_score_,best_model.best_params_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqwFzJNx9YiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.DataFrame(best_model.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQhEyA-x9ZPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_acc = result[['mean_train_Accuracy', 'std_train_Accuracy',\n",
        "                     'mean_test_Accuracy', 'std_test_Accuracy','rank_test_Accuracy',\"param_clf__hidden_layer_sizes\"]].copy()\n",
        "result_acc[\"std_ratio\"] = result_acc.std_test_Accuracy/result_acc.std_train_Accuracy\n",
        "result_acc.sort_values(by=\"rank_test_Accuracy\",ascending=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3nGFyP8Iz-",
        "colab_type": "text"
      },
      "source": [
        "## 1.5 Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-6Qw3D0aDdP",
        "colab_type": "text"
      },
      "source": [
        "**Holdout validation** is actually a specific example of a larger class of validation techniques called **k-fold cross-validation**. While holdout validation is better than train/test validation because the model isn't repeatedly biased towards a specific subset of the data, both models that are trained only use half the available data. K-fold cross validation, on the other hand, takes advantage of a larger proportion of the data during training while still rotating through different subsets of the data to avoid the issues of train/test validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8E3met9d2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# best model\n",
        "predict_first = best_model.best_estimator_.predict(X_test)\n",
        "print(accuracy_score(y_test, predict_first))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}